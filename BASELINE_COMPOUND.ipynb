{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from process import compress_video\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Load 및 추출 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def quadrant_diff(arr, highlight_map):\n",
    "    \"\"\"\n",
    "    Calculate differences within each quadrant of the frame and update highlight_map based on these differences, \n",
    "    using the standard deviation of all differences as the threshold.\n",
    "\n",
    "    Args:\n",
    "    arr (List of np.array): Each element is a 9x256x256x1 numpy array representing a frame.\n",
    "\n",
    "    Returns:\n",
    "    List: Updated highlight_map indicating highlights based on quadrant differences.\n",
    "    \"\"\"\n",
    "    all_diffs = []\n",
    "    \n",
    "    for i in range(len(arr) - 1):\n",
    "        for quadrant in range(4):\n",
    "            # 4개로 분리된 frame의 차이를 계산하는 부분\n",
    "            quarter_shape = (arr[i].shape[1] // 2, arr[i].shape[2] // 2)\n",
    "            x_start = (quadrant % 2) * quarter_shape[0]\n",
    "            y_start = (quadrant // 2) * quarter_shape[1]\n",
    "            current_quarter = arr[i][:, x_start:x_start + quarter_shape[0], y_start:y_start + quarter_shape[1], :]\n",
    "            next_quarter = arr[i + 1][:, x_start:x_start + quarter_shape[0], y_start:y_start + quarter_shape[1], :]\n",
    "\n",
    "            # 각 frame의 차이를 계산\n",
    "            diff = np.abs(current_quarter - next_quarter).sum()\n",
    "            all_diffs.append(diff)\n",
    "    \n",
    "    # 계산된 frame 차이의 표준편차를 임계값으로 설정\n",
    "    threshold = np.std(all_diffs)\n",
    "    \n",
    "    # 해당 임계값을 바탕으로 frame 라벨 update\n",
    "    for i in range(len(arr) - 1):\n",
    "        count_above_threshold = 0\n",
    "        for quadrant in range(4):\n",
    "            quarter_shape = (arr[i].shape[1] // 2, arr[i].shape[2] // 2)\n",
    "            x_start = (quadrant % 2) * quarter_shape[0]\n",
    "            y_start = (quadrant // 2) * quarter_shape[1]\n",
    "            current_quarter = arr[i][:, x_start:x_start + quarter_shape[0], y_start:y_start + quarter_shape[1], :]\n",
    "            next_quarter = arr[i + 1][:, x_start:x_start + quarter_shape[0], y_start:y_start + quarter_shape[1], :]\n",
    "            \n",
    "            diff = np.abs(current_quarter - next_quarter).sum()\n",
    "\n",
    "            if diff > threshold:\n",
    "                count_above_threshold += 1\n",
    "        \n",
    "        if count_above_threshold == 4:\n",
    "            highlight_map[i] += 1\n",
    "        elif count_above_threshold >= 1:\n",
    "            highlight_map[i] = 2\n",
    "        else:\n",
    "            highlight_map[i] = 0\n",
    "\n",
    "    return highlight_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data\n",
    "with open('test.json', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "def parse_annotations(annotations:list, block_num:int):\n",
    "    \"\"\"\n",
    "    Extracts Every Annotation from json label file\n",
    "    \n",
    "    Args:\n",
    "    annotations(List): List of Dictionary for annotations label with highlight and represent\n",
    "\n",
    "    Returns:\n",
    "    List: Whether each block is Highlight or not\n",
    "    \"\"\"\n",
    "    global video_path\n",
    "    highlight_map = {}\n",
    "    \n",
    "    for annot in annotations:\n",
    "        highlights = annot['highlight']\n",
    "        video_path = annot[\"video_path\"]\n",
    "\n",
    "        for num in highlights:\n",
    "            highlight_map[num] = 1\n",
    "            \n",
    "    ret = [0 for _ in range(block_num)]\n",
    "    \n",
    "    for key in highlight_map.keys():\n",
    "        ret[key] = 1\n",
    "\n",
    "    video_frames = np.load(video_path)\n",
    "    ret = quadrant_diff(video_frames, ret)\n",
    "                \n",
    "    return video_frames, ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(\"RuntimeError in set_memory_growth:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "\n",
    "def create_cnn_lstm_model():\n",
    "    # Define the input layer\n",
    "    inputs = Input(shape=(9, 256, 256, 1))\n",
    "\n",
    "    # CNN Layers\n",
    "    x = TimeDistributed(Conv2D(32, (3, 3), activation='relu'))(inputs)\n",
    "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    # LSTM Layer\n",
    "    x = LSTM(50)(x)\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = Dense(3, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Instantiate and compile the model\n",
    "with tf.device('/GPU:0'):  # 첫 번째 GPU를 사용\n",
    "    model = create_cnn_lstm_model()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Trainer 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('processed\\label\\processed_video_data.json', 'r') as file:\n",
    "        json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model):\n",
    "    # data_list = os.listdir(\"processed/video\") # 동영상 데이터 \n",
    "    json_path = 'processed\\label\\processed_video_data.json'\n",
    "\n",
    "    with open(json_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    train_length = int(len(json_data) * 0.7)\n",
    "    \n",
    "    train_data = json_data[:train_length]\n",
    "    test_data = json_data[train_length:]\n",
    "\n",
    "    ## 학습 부분\n",
    "    for i, json_dict in enumerate(train_data):\n",
    "        video, label = parse_annotations(json_dict['annots'], json_dict['three_secs'][-1] + 1)\n",
    "        \n",
    "        X = video # i번 영상의 npy 파일\n",
    "        y = label # 1번 영상에 대한 각 블럭의 하이라이트 여부\n",
    "        \n",
    "        history = model.fit(X, y)\n",
    "        \n",
    "    ## Test\n",
    "    for i in range(len(test_data)):\n",
    "        label = np.array(parse_annotations(json_data[i]['annots'], json_data[i]['three_secs'][-1] + 1))\n",
    "        \n",
    "        X = test_data[i] # i번 영상의 npy 파일\n",
    "        y = label # 1번 영상에 대한 각 블럭의 하이라이트 여부\n",
    "        \n",
    "        model.evaluate(X, y)\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
