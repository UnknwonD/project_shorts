{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from process import compress_video\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Load 및 추출 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def quadrant_diff(arr, highlight_map):\n",
    "    \"\"\"\n",
    "    Calculate differences within each quadrant of the frame and update highlight_map based on these differences, \n",
    "    using the standard deviation of all differences as the threshold.\n",
    "\n",
    "    Args:\n",
    "    arr (List of np.array): Each element is a 9x256x256x1 numpy array representing a frame.\n",
    "\n",
    "    Returns:\n",
    "    List: Updated highlight_map indicating highlights based on quadrant differences.\n",
    "    \"\"\"\n",
    "    all_diffs = []\n",
    "    \n",
    "    for i in range(len(arr) - 1):\n",
    "        for quadrant in range(4):\n",
    "            # 4개로 분리된 frame의 차이를 계산하는 부분\n",
    "            quarter_shape = (arr[i].shape[1] // 2, arr[i].shape[2] // 2)\n",
    "            x_start = (quadrant % 2) * quarter_shape[0]\n",
    "            y_start = (quadrant // 2) * quarter_shape[1]\n",
    "            current_quarter = arr[i][:, x_start:x_start + quarter_shape[0], y_start:y_start + quarter_shape[1], :]\n",
    "            next_quarter = arr[i + 1][:, x_start:x_start + quarter_shape[0], y_start:y_start + quarter_shape[1], :]\n",
    "\n",
    "            # 각 frame의 차이를 계산\n",
    "            diff = np.abs(current_quarter - next_quarter).sum()\n",
    "            all_diffs.append(diff)\n",
    "    \n",
    "    # 계산된 frame 차이의 표준편차를 임계값으로 설정\n",
    "    threshold = np.std(all_diffs)\n",
    "    \n",
    "    # 해당 임계값을 바탕으로 frame 라벨 update\n",
    "    for i in range(len(arr) - 1):\n",
    "        count_above_threshold = 0\n",
    "        for quadrant in range(4):\n",
    "            quarter_shape = (arr[i].shape[1] // 2, arr[i].shape[2] // 2)\n",
    "            x_start = (quadrant % 2) * quarter_shape[0]\n",
    "            y_start = (quadrant // 2) * quarter_shape[1]\n",
    "            current_quarter = arr[i][:, x_start:x_start + quarter_shape[0], y_start:y_start + quarter_shape[1], :]\n",
    "            next_quarter = arr[i + 1][:, x_start:x_start + quarter_shape[0], y_start:y_start + quarter_shape[1], :]\n",
    "            \n",
    "            diff = np.abs(current_quarter - next_quarter).sum()\n",
    "\n",
    "            if diff > threshold:\n",
    "                count_above_threshold += 1\n",
    "        \n",
    "        if count_above_threshold == 4:\n",
    "            highlight_map[i] += 1\n",
    "        elif count_above_threshold >= 1:\n",
    "            highlight_map[i] = 2\n",
    "        else:\n",
    "            highlight_map[i] = 0\n",
    "\n",
    "    return highlight_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data\n",
    "with open('test.json', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "def parse_annotations(annotation:list, block_num:int):\n",
    "    \"\"\"\n",
    "    Extracts Every Annotation from json label file\n",
    "    \n",
    "    Args:\n",
    "    annotations(List): List of Dictionary for annotations label with highlight and represent\n",
    "\n",
    "    Returns:\n",
    "    List: Whether each block is Highlight or not\n",
    "    \"\"\"\n",
    "    global video_path\n",
    "    highlight_map = {}\n",
    "\n",
    "    video_path = annotation[\"video_path\"]\n",
    "    annotations = annotation[\"annots\"]\n",
    "    \n",
    "    for annot in annotations:\n",
    "        highlights = annot['highlight']\n",
    "\n",
    "        for num in highlights:\n",
    "            highlight_map[num] = 1\n",
    "            \n",
    "    ret = [0 for _ in range(block_num)]\n",
    "    \n",
    "    for key in highlight_map.keys():\n",
    "        try:\n",
    "            ret[key] = 1\n",
    "        except:\n",
    "            ret.append(1)\n",
    "\n",
    "    video_frames = np.load(video_path)\n",
    "    ret = quadrant_diff(video_frames, ret)\n",
    "                \n",
    "    return video_frames, ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "\n",
    "def create_cnn_lstm_model():\n",
    "    # Define the input layer\n",
    "    inputs = Input(shape=(9, 256, 256, 1))\n",
    "\n",
    "    # CNN Layers\n",
    "    x = TimeDistributed(Conv2D(32, (3, 3), activation='relu'))(inputs)\n",
    "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    # LSTM Layer\n",
    "    x = LSTM(50)(x)\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Instantiate and compile the model\n",
    "with tf.device('/GPU:0'):  # 첫 번째 GPU를 사용\n",
    "    model = create_cnn_lstm_model()\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 9, 256, 256, 1)]  0         \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 9, 254, 254, 32)  320       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 9, 127, 127, 32)  0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 9, 516128)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                103235800 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103,236,273\n",
      "Trainable params: 103,236,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Trainer 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model):\n",
    "    # data_list = os.listdir(\"processed/video\") # 동영상 데이터 \n",
    "    json_path = 'processed\\label\\processed_video_data.json'\n",
    "    model_path = './video_model.h5'\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        model = load_model(model_path)\n",
    "        print(\"Loaded existing model.\")\n",
    "    else:\n",
    "        print(\"No existing model found, starting training new model.\")\n",
    "\n",
    "    with open(json_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    train_length = int(len(json_data) * 0.7)\n",
    "    \n",
    "    train_data = json_data[:train_length]\n",
    "    test_data = json_data[train_length:]\n",
    "    all_histories = []\n",
    "\n",
    "    ## 학습 부분\n",
    "    for i, json_dict in enumerate(train_data):\n",
    "        video, label = parse_annotations(json_dict, json_dict['three_secs'][-1])\n",
    "        \n",
    "        X = video # i번 영상의 npy 파일\n",
    "        y = np.array(label) # 1번 영상에 대한 각 블럭의 하이라이트 여부\n",
    "\n",
    "        min_length = min(len(X), len(y))\n",
    "        X, y = X[:min_length], y[:min_length]\n",
    "\n",
    "        y = to_categorical(y, num_classes=3)\n",
    "        \n",
    "        history = model.fit(X, y, epochs=10, verbose=0)\n",
    "        all_histories.append(history.history)  # Save history\n",
    "        model.save('./video_model.h5')\n",
    "\n",
    "    ## Test\n",
    "    # for i in range(len(test_data)):\n",
    "    #     label = np.array(parse_annotations(json_data[i]['annots'], json_data[i]['three_secs'][-1] + 1))\n",
    "        \n",
    "    #     X = test_data[i] # i번 영상의 npy 파일\n",
    "    #     y = label # 1번 영상에 대한 각 블럭의 하이라이트 여부\n",
    "        \n",
    "    #     print(f\"Test {i} :: {model.evaluate(X, y)}\")\n",
    "\n",
    "    return model, all_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(histories):\n",
    "    epochs = range(1, len(histories[0]['loss']) + 1)\n",
    "    all_loss = [h['loss'] for h in histories]\n",
    "    all_acc = [h['accuracy'] for h in histories]\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i, loss in enumerate(all_loss):\n",
    "        plt.plot(epochs, loss, label=f'Training {i+1}')\n",
    "    plt.title('Loss over training videos')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for i, acc in enumerate(all_acc):\n",
    "        plt.plot(epochs, acc, label=f'Training {i+1}')\n",
    "    plt.title('Accuracy over training videos')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing model.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model/time_distributed_1/max_pooling2d/MaxPool/MaxPoolGrad' defined at (most recent call last):\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\daeho\\AppData\\Local\\Temp\\ipykernel_40680\\2640403355.py\", line 1, in <module>\n      model_traied, history = trainer(model)\n    File \"C:\\Users\\daeho\\AppData\\Local\\Temp\\ipykernel_40680\\504081248.py\", line 33, in trainer\n      history = model.fit(X, y, epochs=10, verbose=0)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/time_distributed_1/max_pooling2d/MaxPool/MaxPoolGrad'\nOOM when allocating tensor with shape[288,254,254,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/time_distributed_1/max_pooling2d/MaxPool/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7633]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_traied, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 33\u001b[0m, in \u001b[0;36mtrainer\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     29\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X[:min_length], y[:min_length]\n\u001b[0;32m     31\u001b[0m y \u001b[38;5;241m=\u001b[39m to_categorical(y, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m all_histories\u001b[38;5;241m.\u001b[39mappend(history\u001b[38;5;241m.\u001b[39mhistory)  \u001b[38;5;66;03m# Save history\u001b[39;00m\n\u001b[0;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./video_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model/time_distributed_1/max_pooling2d/MaxPool/MaxPoolGrad' defined at (most recent call last):\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\daeho\\AppData\\Local\\Temp\\ipykernel_40680\\2640403355.py\", line 1, in <module>\n      model_traied, history = trainer(model)\n    File \"C:\\Users\\daeho\\AppData\\Local\\Temp\\ipykernel_40680\\504081248.py\", line 33, in trainer\n      history = model.fit(X, y, epochs=10, verbose=0)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"c:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/time_distributed_1/max_pooling2d/MaxPool/MaxPoolGrad'\nOOM when allocating tensor with shape[288,254,254,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/time_distributed_1/max_pooling2d/MaxPool/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7633]"
     ]
    }
   ],
   "source": [
    "model_traied, history = trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Audio model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "def create_simple_cnn():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               589952    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 683,587\n",
      "Trainable params: 683,587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_audio = create_simple_cnn()\n",
    "model_audio.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data\n",
    "with open('test.json', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "def parse_annotations(annotation:list, block_num:int):\n",
    "    \"\"\"\n",
    "    Extracts Every Annotation from json label file\n",
    "    \n",
    "    Args:\n",
    "    annotations(List): List of Dictionary for annotations label with highlight and represent\n",
    "\n",
    "    Returns:\n",
    "    List: Whether each block is Highlight or not\n",
    "    \"\"\"\n",
    "    global video_path\n",
    "    highlight_map = {}\n",
    "\n",
    "    video_path = annotation[\"audio_path\"]\n",
    "    annotations = annotation[\"annots\"]\n",
    "    \n",
    "    for annot in annotations:\n",
    "        highlights = annot['highlight']\n",
    "\n",
    "        for num in highlights:\n",
    "            highlight_map[num] = 1\n",
    "            \n",
    "    ret = [0 for _ in range(block_num)]\n",
    "    \n",
    "    for key in highlight_map.keys():\n",
    "        try:\n",
    "            ret[key] = 1\n",
    "        except:\n",
    "            ret.append(1)\n",
    "\n",
    "    video_frames = np.load(video_path)\n",
    "    ret = quadrant_diff(video_frames, ret)\n",
    "                \n",
    "    return video_frames, ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model):\n",
    "    # data_list = os.listdir(\"processed/video\") # 동영상 데이터 \n",
    "    json_path = 'processed\\label\\processed_video_data.json'\n",
    "    model_path = './video_model.h5'\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        model = load_model(model_path)\n",
    "        print(\"Loaded existing model.\")\n",
    "    else:\n",
    "        print(\"No existing model found, starting training new model.\")\n",
    "\n",
    "    with open(json_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    train_length = int(len(json_data) * 0.7)\n",
    "    \n",
    "    train_data = json_data[:train_length]\n",
    "    test_data = json_data[train_length:]\n",
    "    all_histories = []\n",
    "\n",
    "    ## 학습 부분\n",
    "    for i, json_dict in enumerate(train_data):\n",
    "        video, label = parse_annotations(json_dict, json_dict['three_secs'][-1])\n",
    "        \n",
    "        X = video # i번 영상의 npy 파일\n",
    "        y = np.array(label) # 1번 영상에 대한 각 블럭의 하이라이트 여부\n",
    "\n",
    "        min_length = min(len(X), len(y))\n",
    "        X, y = X[:min_length], y[:min_length]\n",
    "\n",
    "        y = to_categorical(y, num_classes=3)\n",
    "        \n",
    "        history = model.fit(X, y, epochs=10, verbose=0)\n",
    "        all_histories.append(history.history)  # Save history\n",
    "        model.save('./audio_model.h5')\n",
    "\n",
    "    return model, all_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_audio\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 7\u001b[0m, in \u001b[0;36mtrainer\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./video_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path):\n\u001b[1;32m----> 7\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded existing model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\saving\\save.py:241\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    237\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFilepath looks like a hdf5 file but h5py is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m             )\n\u001b[1;32m--> 241\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhdf5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile):\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hdf5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    248\u001b[0m         filepath, custom_objects, \u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    249\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\saving\\hdf5_format.py:253\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    249\u001b[0m optimizer_weight_values \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    250\u001b[0m     load_optimizer_weights_from_hdf5_group(f)\n\u001b[0;32m    251\u001b[0m )\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 253\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer_weight_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in loading the saved optimizer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate. As a result, your model is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting with a freshly initialized \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:165\u001b[0m, in \u001b[0;36mAdam.set_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(weights) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m num_vars \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    164\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights[: \u001b[38;5;28mlen\u001b[39m(params)]\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:1310\u001b[0m, in \u001b[0;36mOptimizerV2.set_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m weight_value_tuples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1310\u001b[0m param_values \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pv, p, w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(param_values, params, weights):\n\u001b[0;32m   1312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pv\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m w\u001b[38;5;241m.\u001b[39mshape:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\backend.py:4240\u001b[0m, in \u001b[0;36mbatch_get_value\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m   4228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the value of more than one tensor variable.\u001b[39;00m\n\u001b[0;32m   4229\u001b[0m \n\u001b[0;32m   4230\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4237\u001b[0m \u001b[38;5;124;03m    RuntimeError: If this method is called inside defun.\u001b[39;00m\n\u001b[0;32m   4238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 4240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [x\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tensors]\n\u001b[0;32m   4241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m   4242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get value inside Tensorflow graph function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\daeho\\anaconda3\\envs\\tf_ds\\lib\\site-packages\\keras\\backend.py:4240\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   4228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the value of more than one tensor variable.\u001b[39;00m\n\u001b[0;32m   4229\u001b[0m \n\u001b[0;32m   4230\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4237\u001b[0m \u001b[38;5;124;03m    RuntimeError: If this method is called inside defun.\u001b[39;00m\n\u001b[0;32m   4238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 4240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tensors]\n\u001b[0;32m   4241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m   4242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get value inside Tensorflow graph function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer(model_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
